ðŸ”¹ Project Title

Credit Card Fraud Detection System (ML + FastAPI + Docker)

ðŸ”¹ Overview

This project is an end-to-end fraud detection system built using classical machine learning models and deployed as a production-style inference service.

The system:

Trains and evaluates multiple fraud detection models

Converts probabilistic outputs into business decisions (BLOCK / ALLOW)

Serves predictions via a FastAPI REST API

Is fully containerized using Docker for reproducible deployment

The design is inspired by real-world fintech systems (e.g., Stripe-style risk engines) where model outputs are separated from decision logic.

ðŸ”¹ Problem Statement

Credit card fraud detection is a highly imbalanced classification problem, where fraudulent transactions are rare but extremely costly.

Key challenges:

Severe class imbalance

Need for high recall at low false-positive rates

Requirement for explainable, controllable decisioning

Production constraints (latency, reproducibility, reliability)

This project addresses these challenges using a multi-model, threshold-based risk scoring approach.

ðŸ”¹ Dataset

Dataset: European Credit Card Transactions

Source: Public Kaggle dataset

Records: ~285,000 transactions

Fraud rate: ~0.17%

Features:

V1â€“V28: PCA-transformed transaction features

Time: Seconds since first transaction

Amount: Transaction amount

Class: Fraud label (1 = fraud, 0 = legitimate)


ðŸ”¹ System Architecture

Incoming Transaction (JSON)
        |
        v
Feature Validation
        |
        v
Preprocessing
(StandardScaler for LR)
        |
        v
Model Scoring
(LR / RF / Ensemble)
        |
        v
Threshold-based Decision
(BLOCK / ALLOW)
        |
        v
FastAPI Response

ðŸ”¹ Models Used
Model	Purpose
Logistic Regression	Interpretable, stable baseline
Random Forest	Non-linear pattern capture
Ensemble	Weighted combination of LR + RF

The system supports runtime model switching:

lr â†’ Logistic Regression

rf â†’ Random Forest

ensemble â†’ Combined score

ðŸ”¹ Decision Logic

Models output a fraud probability, not a decision.

Final decisions are made using a configurable threshold:

fraud_score â‰¥ threshold  â†’ BLOCK
fraud_score < threshold  â†’ ALLOW

This allows business teams to tune risk tolerance without retraining models.

Example:

Lower threshold â†’ higher fraud catch rate, more false positives

Higher threshold â†’ fewer false positives, more fraud leakage

ðŸ”¹ Evaluation Metrics

Fraud detection is evaluated using appropriate metrics for imbalanced data:

ROC-AUC

Precisionâ€“Recall AUC

Precision / Recall at selected thresholds

Emphasis is placed on recall under constrained false-positive rates, aligning with real-world fraud systems.

(Exact metrics can be added here if you want to include numbers)

ðŸ”¹ API Endpoints

Health Check
GET /health

Fraud Prediction
POST /predict

Example request:
{
  "transaction": {
    "Time": 0.0,
    "V1": -1.359807,
    "V2": -0.072781,
    "...": "...",
    "Amount": 149.62
  },
  "model": "ensemble",
  "threshold": 0.1
}

Example response:
{
  "fraud_score": 0.032,
  "decision": "ALLOW",
  "used_model": "ensemble",
  "threshold": 0.1
}


ðŸ”¹ Project Structure

fraud_engine/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ scaler.joblib
â”‚   â”œâ”€â”€ lr_model.joblib
â”‚   â”œâ”€â”€ rf_model.joblib
â”‚   â””â”€â”€ feature_columns.json
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ main.py
â”‚       â””â”€â”€ schemas.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda.ipynb
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ðŸ”¹ Running the Project (Docker)

Build the image
docker build -t fraud-engine .

Run the container:
docker run -p 8000:8000 fraud-engine

Access API

Health: http://127.0.0.1:8000/health

Swagger UI: http://127.0.0.1:8000/docs

ðŸ”¹ Key Design Decisions

Threshold-based decisioning instead of fixed probability cutoff

Model switching and ensemble support for experimentation

Separation of ML logic and business policy

Containerized deployment for reproducibility

ðŸ”¹ Future Improvements

Add experiment tracking (MLflow)

Add request logging and monitoring

Implement data drift detection

Add CI/CD pipeline

Deploy on cloud infrastructure

ðŸ”¹ Why This Project Matters

This project demonstrates:

Practical machine learning modeling

Production-style ML system design

API-based inference

MLOps fundamentals (Docker, reproducibility)

Business-aware decision making